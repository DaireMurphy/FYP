{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model - Large PreTrained Google News bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "GoogleModel = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.8543272018432617),\n",
       " ('teenage_girl', 0.7927976846694946),\n",
       " ('woman', 0.7494641542434692),\n",
       " ('teenager', 0.7172499299049377),\n",
       " ('schoolgirl', 0.7075953483581543),\n",
       " ('teenaged_girl', 0.6650916934013367),\n",
       " ('daughter', 0.6489864587783813),\n",
       " ('mother', 0.64781653881073),\n",
       " ('toddler', 0.6473966240882874),\n",
       " ('girls', 0.6154742240905762)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleModel.most_similar('girl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placing the results of the most_similar into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       woman\n",
      "1                         boy\n",
      "2                    teenager\n",
      "3                teenage_girl\n",
      "4                        girl\n",
      "5    suspected_purse_snatcher\n",
      "6                      robber\n",
      "7             Robbery_suspect\n",
      "8                   teen_ager\n",
      "9                         men\n",
      "Name: Most Similar, dtype: object\n"
     ]
    }
   ],
   "source": [
    "manList = GoogleModel.most_similar(positive=['man'], topn=15)\n",
    "dfman = pd.DataFrame(manList, columns = ['Most Similar' , 'Vector Accuracy'])\n",
    "print (dfman['Most Similar'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the most similar words from a list of words using a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Word: Trump\n",
      "0                Donald_Trump\n",
      "1    impersonator_entertained\n",
      "2                Ivanka_Trump\n",
      "3                      Ivanka\n",
      "4          mogul_Donald_Trump\n",
      "5                 Trump_Tower\n",
      "6                     Kepcher\n",
      "7    billionaire_Donald_Trump\n",
      "8                   Trumpster\n",
      "9         tycoon_Donald_Trump\n",
      "Name: Most Similar, dtype: object\n",
      "-- Word: Obama\n",
      "0              Barack_Obama\n",
      "1    President_Barack_Obama\n",
      "2                    McCain\n",
      "3                   Clinton\n",
      "4          Illinois_senator\n",
      "5                     Biden\n",
      "6                      Bush\n",
      "7                    Barack\n",
      "8               White_House\n",
      "9        elect_Barack_Obama\n",
      "Name: Most Similar, dtype: object\n",
      "-- Word: Clinton\n",
      "0            Hillary_Clinton\n",
      "1                      Obama\n",
      "2               Bill_Clinton\n",
      "3     Hillary_Rodham_Clinton\n",
      "4       Sen._Hillary_Clinton\n",
      "5                    Hillary\n",
      "6    Senator_Hillary_Clinton\n",
      "7                     McCain\n",
      "8                   Clintons\n",
      "9               Barack_Obama\n",
      "Name: Most Similar, dtype: object\n"
     ]
    }
   ],
   "source": [
    "words = [\"Trump\", \"Obama\", \"Clinton\" ]\n",
    "for word in words:\n",
    "    print(\"-- Word: %s\" % word)\n",
    "    result = GoogleModel.most_similar(positive=word)\n",
    "    dfloop = pd.DataFrame(result, columns = ['Most Similar' , 'Vector Accuracy'])\n",
    "    print (dfloop['Most Similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drum', 0.6940563321113586),\n",
       " ('drumming', 0.513245701789856),\n",
       " ('music', 0.5001342296600342),\n",
       " ('Drum', 0.40797555446624756),\n",
       " ('hip_hop', 0.4001891314983368),\n",
       " ('bands', 0.3928840458393097),\n",
       " ('bhangra', 0.3885735273361206),\n",
       " ('reggae_dancehall', 0.38298097252845764),\n",
       " ('reggae', 0.38292473554611206),\n",
       " ('reggae_hip_hop', 0.3807390034198761)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2 = GoogleModel['music'] - GoogleModel['piano'] + GoogleModel['drum']\n",
    "GoogleModel.most_similar([vec2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Self Trained Reddit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in a csv of a medium size to a dataframe, and sepreating out the required 'Title' column to be used to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>date_created</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>over_18</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201232046</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1201232075</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201232523</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201233290</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Jump-start economy: Give health care to all</td>\n",
       "      <td>False</td>\n",
       "      <td>fadi420</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201274720</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Council of Europe bashes EU&amp;UN terror blacklist</td>\n",
       "      <td>False</td>\n",
       "      <td>mhermans</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_created date_created  up_votes  down_votes  \\\n",
       "0    1201232046   2008-01-25         3           0   \n",
       "1    1201232075   2008-01-25         2           0   \n",
       "2    1201232523   2008-01-25         3           0   \n",
       "3    1201233290   2008-01-25         1           0   \n",
       "4    1201274720   2008-01-25         4           0   \n",
       "\n",
       "                                             title  over_18    author  \\\n",
       "0                Scores killed in Pakistan clashes    False     polar   \n",
       "1                 Japan resumes refuelling mission    False     polar   \n",
       "2                  US presses Egypt on Gaza border    False     polar   \n",
       "3     Jump-start economy: Give health care to all     False   fadi420   \n",
       "4  Council of Europe bashes EU&UN terror blacklist    False  mhermans   \n",
       "\n",
       "   subreddit  \n",
       "0  worldnews  \n",
       "1  worldnews  \n",
       "2  worldnews  \n",
       "3  worldnews  \n",
       "4  worldnews  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReddit = pd.read_csv('RedditNews.csv')\n",
    "dfReddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509236,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTitles = dfReddit[\"title\"]\n",
    "newTitles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the newTitles list and print the first 10 objects in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Scores', 'killed', 'in', 'Pakistan', 'clashes'],\n",
       " ['Japan', 'resumes', 'refuelling', 'mission'],\n",
       " ['US', 'presses', 'Egypt', 'on', 'Gaza', 'border'],\n",
       " ['Jump-start', 'economy', ':', 'Give', 'health', 'care', 'to', 'all'],\n",
       " ['Council', 'of', 'Europe', 'bashes', 'EU', '&', 'UN', 'terror', 'blacklist'],\n",
       " ['Hay',\n",
       "  'presto',\n",
       "  '!',\n",
       "  'Farmer',\n",
       "  'unveils',\n",
       "  'the',\n",
       "  'illegal',\n",
       "  'mock-Tudor',\n",
       "  'castle',\n",
       "  'he',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'hide',\n",
       "  'behind',\n",
       "  '40ft',\n",
       "  'hay',\n",
       "  'bales'],\n",
       " ['Strikes',\n",
       "  ',',\n",
       "  'Protests',\n",
       "  'and',\n",
       "  'Gridlock',\n",
       "  'at',\n",
       "  'the',\n",
       "  'Poland-Ukraine',\n",
       "  'Border'],\n",
       " ['The', 'U.N', '.', 'Mismanagement', 'Program'],\n",
       " ['Nicolas', 'Sarkozy', 'threatens', 'to', 'sue', 'Ryanair'],\n",
       " ['US',\n",
       "  'plans',\n",
       "  'for',\n",
       "  'missile',\n",
       "  'shields',\n",
       "  'in',\n",
       "  'Polish',\n",
       "  'town',\n",
       "  'met',\n",
       "  'with',\n",
       "  'resistance',\n",
       "  '[',\n",
       "  'video',\n",
       "  ']']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsVec = [nltk.word_tokenize(title) for title in newTitles]\n",
    "newsVec[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word2Vec, assign each word in the model a vector of size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RedditModel = Word2Vec(newsVec,min_count=1,size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.898088812828064),\n",
       " ('teenager', 0.8351012468338013),\n",
       " ('boy', 0.8271929025650024),\n",
       " ('girl', 0.8181493282318115),\n",
       " ('couple', 0.7930596470832825),\n",
       " ('teen', 0.752565324306488),\n",
       " ('mother', 0.7476451992988586),\n",
       " ('doctor', 0.7413562536239624),\n",
       " ('teacher', 0.7396202087402344),\n",
       " ('policeman', 0.7272433638572693)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RedditModel.wv.most_similar('man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Small Wiki Dump bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "WikiModel = KeyedVectors.load_word2vec_format('wiki100k-w2v.cbow.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.7120599746704102),\n",
       " ('destiny', 0.7029043436050415),\n",
       " ('love', 0.6940176486968994),\n",
       " ('lovers', 0.6887222528457642),\n",
       " ('sorry', 0.6821417808532715),\n",
       " ('teenage', 0.6736853718757629),\n",
       " ('beasts', 0.667998194694519),\n",
       " ('mercy', 0.6590928435325623),\n",
       " ('hello', 0.657588005065918),\n",
       " ('restless', 0.6566181182861328)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiModel.most_similar('girl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Comparisons of the 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.868048906326294),\n",
       " ('puppy', 0.8106427192687988),\n",
       " ('pit_bull', 0.7803961038589478),\n",
       " ('pooch', 0.7627377510070801),\n",
       " ('cat', 0.7609456777572632),\n",
       " ('golden_retriever', 0.7500902414321899),\n",
       " ('German_shepherd', 0.7465174198150635),\n",
       " ('Rottweiler', 0.7437615394592285),\n",
       " ('beagle', 0.7418622374534607),\n",
       " ('pup', 0.7406911253929138)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleModel.most_similar('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horse', 0.7701406478881836),\n",
       " ('pet', 0.770033597946167),\n",
       " ('cat', 0.7622345685958862),\n",
       " ('baby', 0.76194167137146),\n",
       " ('naked', 0.752766489982605),\n",
       " ('corpse', 0.7394227981567383),\n",
       " ('crocodile', 0.7339233756065369),\n",
       " ('penis', 0.7293257713317871),\n",
       " ('pig', 0.7262090444564819),\n",
       " ('lion', 0.7227792739868164)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RedditModel.wv.most_similar('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.7068554162979126),\n",
       " ('rabbits', 0.6879082918167114),\n",
       " ('cat', 0.6614759564399719),\n",
       " ('cats', 0.6565462350845337),\n",
       " ('anthropomorphic', 0.6554036140441895),\n",
       " ('t_shirts', 0.6497201919555664),\n",
       " ('beast', 0.6489153504371643),\n",
       " ('coyote', 0.6422343254089355),\n",
       " ('flesh', 0.6411483883857727),\n",
       " ('beasts', 0.6408825516700745)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiModel.most_similar('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
